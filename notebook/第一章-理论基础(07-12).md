

# 第一章 理论基础



![image-20230712202440431](/Users/leonzhu/Library/Application Support/typora-user-images/image-20230712202440431.png)



![image-20230712202631750](/Users/leonzhu/Library/Application Support/typora-user-images/image-20230712202631750.png)





![image-20230712203713983](/Users/leonzhu/Library/Application Support/typora-user-images/image-20230712203713983.png)



![image-20230712204827214](/Users/leonzhu/Library/Application Support/typora-user-images/image-20230712204827214.png)





![image-20230712210918701](/Users/leonzhu/Library/Application Support/typora-user-images/image-20230712210918701.png)



![image-20230712211009159](/Users/leonzhu/Library/Application Support/typora-user-images/image-20230712211009159.png)



这篇文章会比较好理解 Attention 的本质

https://towardsdatascience.com/attn-illustrated-attention-5ec4ad276ee3#0458%EF%BC%8C



![image-20230712211900336](/Users/leonzhu/Library/Application Support/typora-user-images/image-20230712211900336.png)



![image-20230712212006408](/Users/leonzhu/Library/Application Support/typora-user-images/image-20230712212006408.png)

